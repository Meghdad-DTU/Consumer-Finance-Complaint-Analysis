{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paladin/Downloads/Consumer-Finance-Complaint-Analysis'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    from_date: str\n",
    "    to_date: str    \n",
    "    feature_store_dir: Path \n",
    "    downloaded_dir: Path\n",
    "    failed_downloaded_dir: Path            \n",
    "    metadata_file_path: Path\n",
    "    min_start_date: str\n",
    "    file_name: str    \n",
    "    datasource_url: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from financeComplaint.constants import *\n",
    "from financeComplaint.utils import read_yaml_file, write_yaml_file, create_directories\n",
    "from financeComplaint.entity.metadata_entity import DataIngestionMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,                 \n",
    "                 params_filepath=PARAMS_FILE_PATH,\n",
    "                 saved_modelpath=SAVED_MODEL_PATH,\n",
    "                 ):\n",
    "       \n",
    "        self.config = read_yaml_file(config_filepath)\n",
    "        self.params = read_yaml_file(params_filepath)\n",
    "        self.saved_modelpath = saved_modelpath\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        self.timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S') \n",
    "        \n",
    "    \n",
    "    def get_data_ingestion_config(self, from_date: str=None, to_date: str=None) -> DataIngestionConfig:\n",
    "        \"\"\"\n",
    "        from date can not be less than min start date\n",
    "\n",
    "        if to_date is not provided automatically current date will become to date\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        config = self.config.data_ingestion\n",
    "        SUB_ROOT_DIR = os.path.join(config.ROOT_DIR, self.timestamp)\n",
    "        DOWNLOADED_DIR = os.path.join(SUB_ROOT_DIR,'downloaded_files')\n",
    "        FAILED_DOWNLOADED_DIR = os.path.join(SUB_ROOT_DIR,'failed_downloaded_files')\n",
    "        \n",
    "\n",
    "        create_directories([config.ROOT_DIR, \n",
    "                            config.FEATURE_STORE_DIR,\n",
    "                            DOWNLOADED_DIR, \n",
    "                            FAILED_DOWNLOADED_DIR, \n",
    "                            ])\n",
    "    \n",
    "        def validate(date_text):\n",
    "            try:\n",
    "                if date_text != datetime.strptime(date_text, \"%Y-%m-%d\").strftime('%Y-%m-%d'):\n",
    "                    raise ValueError\n",
    "                return True\n",
    "            except ValueError:\n",
    "                return False\n",
    "        \n",
    "          \n",
    "        min_start_date= config.MIN_START_DATE \n",
    "        if  not validate(min_start_date):\n",
    "            raise Exception(f\"WARNING: Minimum start date: {min_start_date} does not have correct format!\")    \n",
    "        \n",
    "        if from_date is None:\n",
    "            from_date = min_start_date \n",
    "        else:\n",
    "            if not validate(from_date):\n",
    "                raise Exception(f\"WARNING: From date: {from_date} does not have correct format!\")\n",
    "        \n",
    "        if from_date < min_start_date:\n",
    "            from_date = min_start_date\n",
    "        \n",
    "        if to_date is None:\n",
    "            to_date = datetime.now().strftime(\"%Y-%m-%d\")  \n",
    "        \n",
    "        else:\n",
    "            if not validate(to_date):\n",
    "                raise Exception(f\"WARNING: To date : {to_date} does not have correct format!\") \n",
    "\n",
    "        data_ingestion_metadata= DataIngestionMetadata(config.METADATA_FILE_PATH)\n",
    "\n",
    "        if data_ingestion_metadata.is_metadata_file_exist:\n",
    "            metadata_info= data_ingestion_metadata.get_metadata_info()\n",
    "            from_date = metadata_info.to_date\n",
    "        \n",
    "        \n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir = config.ROOT_DIR,\n",
    "            from_date= from_date,\n",
    "            to_date= to_date,\n",
    "            feature_store_dir= config.FEATURE_STORE_DIR,   \n",
    "            downloaded_dir = DOWNLOADED_DIR,\n",
    "            failed_downloaded_dir= FAILED_DOWNLOADED_DIR,                     \n",
    "            metadata_file_path= config.METADATA_FILE_PATH,\n",
    "            min_start_date= config.MIN_START_DATE,  \n",
    "            file_name= config.FILE_NAME,         \n",
    "            datasource_url= config.DATASOURCE_URL, \n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from financeComplaint.logger import logging\n",
    "from financeComplaint.exception import CustomException\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import uuid\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from financeComplaint.entity.artifact_entity import DataIngestionArtifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen= True)\n",
    "class DownloadURL:\n",
    "    url: str\n",
    "    file_path: Path\n",
    "    n_retry: int\n",
    "\n",
    "\n",
    "class DataIngestion:\n",
    "    # Used to download data in chunks\n",
    "    def __init__(self, config: DataIngestionConfig, n_retry: int=5):\n",
    "        \"\"\"\n",
    "        config: Data Ingestion configuration\n",
    "        n_retry: number of retry failed should be tried to download  in case of failure encountered        \n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.config = config\n",
    "            self.failed_download_urls: List[DownloadURL] = []\n",
    "            self.n_retry = n_retry\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def get_required_interval(self):\n",
    "        try:\n",
    "            start_date = datetime.strptime(self.config.from_date, \"%Y-%m-%d\")\n",
    "            end_date = datetime.strptime(self.config.to_date, \"%Y-%m-%d\")\n",
    "            n_diff_days = (end_date - start_date).days\n",
    "            freq = None\n",
    "            if n_diff_days > 365:\n",
    "                freq = \"Y\"\n",
    "            elif n_diff_days > 30:\n",
    "                freq = \"M\"\n",
    "            elif n_diff_days > 7:\n",
    "                freq = \"W\"\n",
    "            logging.debug(f\"{n_diff_days} hence freq: {freq}\")\n",
    "            if freq is None:\n",
    "                intervals = pd.date_range(start=self.config.from_date,\n",
    "                                        end=self.config.to_date,\n",
    "                                        periods=2).astype('str').tolist()\n",
    "                \n",
    "            else:\n",
    "                intervals = pd.date_range(start=self.config.from_date,\n",
    "                                        end=self.config.to_date,\n",
    "                                        freq=freq).astype('str').tolist()\n",
    "\n",
    "            logging.debug(f\"Prepared Interval: {intervals}\")\n",
    "            if self.config.to_date not in intervals:\n",
    "                intervals.append(self.config.to_date)\n",
    "            return intervals\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "    \n",
    "    def download_files(self, n_day_interval_url: int = None):\n",
    "        try:\n",
    "            required_interval = self.get_required_interval()\n",
    "            logging.info(\"Started downloading files\")\n",
    "            for index in range(1, len(required_interval)):\n",
    "                from_date, to_date = required_interval[index - 1], required_interval[index]\n",
    "                logging.debug(f\"Generating data download url between {from_date} and {to_date}\")\n",
    "                datasource_url: str = self.config.datasource_url\n",
    "                url = datasource_url.replace(\"[to_date]\", to_date).replace(\"[from_date]\", from_date)\n",
    "                file_name = f\"{self.config.file_name}_{from_date}_{to_date}.json\"\n",
    "                logging.debug(f\"Url: {url}\")\n",
    "                file_name = f\"{self.config.file_name}_{from_date}_{to_date}.json\"\n",
    "                file_path = os.path.join(self.config.downloaded_dir, file_name)\n",
    "                download_url = DownloadURL(url=url, file_path=file_path, n_retry=self.n_retry)   \n",
    "                self.download_data(download_url=download_url)         \n",
    "            logging.info(f\"File download completed!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def download_data(self, download_url: DownloadURL):\n",
    "        try:\n",
    "            logging.info(f\"Starting download operation: {download_url}\")\n",
    "            download_dir = os.path.dirname(download_url.file_path)\n",
    "\n",
    "            # creating download directory\n",
    "            os.makedirs(download_dir, exist_ok=True)\n",
    "            # downloading data\n",
    "            data = requests.get(download_url.url, params={'User-agent': f'your bot {uuid.uuid4()}'})\n",
    "            try:\n",
    "                logging.info(f\"Started writing downloaded data into json file: {download_url.file_path}\")\n",
    "                # saving downloaded data into hard disk\n",
    "                with open(download_url.file_path, \"w\") as file_obj:\n",
    "                    finance_complaint_data = list(map(lambda x: x[\"_source\"],\n",
    "                                                      filter(lambda x: \"_source\" in x.keys(),\n",
    "                                                             json.loads(data.content)))\n",
    "                                                  )\n",
    "\n",
    "                    json.dump(finance_complaint_data, file_obj)\n",
    "                logging.info(f\"Downloaded data has been written into file: {download_url.file_path}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                logging.info(\"Failed to download hence retry again!\")\n",
    "                # removing file failed file exist\n",
    "                if os.path.exists(download_url.file_path):\n",
    "                    os.remove(download_url.file_path)\n",
    "                \n",
    "                self.retry_download_data(data, download_url=download_url)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    \n",
    "    def retry_download_data(self, data, download_url: DownloadURL):\n",
    "        try:\n",
    "            # if retry still possible try else return the response\n",
    "            if download_url.n_retry == 0:\n",
    "                self.failed_download_urls.append(download_url)\n",
    "                logging.info(f\"Unable to download file {download_url.url}\")\n",
    "                return\n",
    "            # to handle throatling requestion and can be slove if we wait for some second.\n",
    "            content = data.content.decode(\"utf-8\")\n",
    "            # The .findall() method iterates over a string to find a subset of characters that match a specified pattern.\n",
    "            wait_second = re.findall(r'\\d+', content)\n",
    "            \n",
    "            if len(wait_second) > 0:\n",
    "                time.sleep(int(wait_second[0]) + 2)\n",
    "\n",
    "            # Writing response to understand why request was failed\n",
    "            failed_file_path = os.path.join(self.config.failed_downloaded_dir, os.path.basename(download_url.file_path))\n",
    "            os.makedirs(self.config.failed_downloaded_dir, exist_ok=True)\n",
    "            with open(failed_file_path, \"wb\") as file_obj:\n",
    "                file_obj.write(data.content)\n",
    "\n",
    "             # calling download function again to retry\n",
    "            download_url = DownloadURL(download_url.url, file_path=download_url.file_path, n_retry=download_url.n_retry - 1)\n",
    "            self.download_data(download_url=download_url)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "\n",
    "    def initiate_data_ingestion(self) -> DataIngestionConfig:\n",
    "        try:\n",
    "            logging.info(f\"Started downloading json file!\")\n",
    "            if self.config.from_date != self.config.to_date:\n",
    "                self.download_files()\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.initiate_data_ingestion()\n",
    "except Exception as e:\n",
    "    raise CustomException(e, sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
