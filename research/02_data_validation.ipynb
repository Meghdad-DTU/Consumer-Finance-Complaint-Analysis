{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paladin/Downloads/Consumer-Finance-Complaint-Analysis'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    feature_store_file_path: Path\n",
    "    accepted_data_dir: Path\n",
    "    rejected_data_dir: Path\n",
    "    file_name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from financeComplaint.constants import *\n",
    "from financeComplaint.utils import read_yaml_file, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,                 \n",
    "                 params_filepath=PARAMS_FILE_PATH,\n",
    "                 saved_modelpath=SAVED_MODEL_PATH,\n",
    "                 ):\n",
    "       \n",
    "        self.config = read_yaml_file(config_filepath)\n",
    "        self.params = read_yaml_file(params_filepath)\n",
    "        self.saved_modelpath = saved_modelpath\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        self.timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        SUB_ROOT_DIR = os.path.join(config.ROOT_DIR, self.timestamp)\n",
    "        ACCEPTED_DATA_DIR = os.path.join(SUB_ROOT_DIR, 'accepted_data')\n",
    "        REJECTED_DATA_DIR = os.path.join(SUB_ROOT_DIR, 'rejected_data')\n",
    "        FEATURE_STORE_FILE_PATH = os.path.join(self.config.data_ingestion.FEATURE_STORE_DIR,\n",
    "                                               self.config.data_ingestion.FILE_NAME)\n",
    "\n",
    "        create_directories([config.ROOT_DIR, ACCEPTED_DATA_DIR, REJECTED_DATA_DIR ])\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir = config.ROOT_DIR,\n",
    "            feature_store_file_path= FEATURE_STORE_FILE_PATH,\n",
    "            accepted_data_dir = ACCEPTED_DATA_DIR,\n",
    "            rejected_data_dir = REJECTED_DATA_DIR,\n",
    "            file_name= config.FILE_NAME,\n",
    "\n",
    "        )\n",
    "\n",
    "        return data_validation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/10/12 15:54:17 WARN Utils: Your hostname, ds-xps resolves to a loopback address: 127.0.1.1; using 192.168.2.16 instead (on interface wlp2s0)\n",
      "23/10/12 15:54:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/paladin/Downloads/Consumer-Finance-Complaint-Analysis/venv/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/paladin/.ivy2/cache\n",
      "The jars for the packages stored in: /home/paladin/.ivy2/jars\n",
      "com.amazonaws#aws-java-sdk added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f79a42e3-595b-4a4d-9069-c5348c381c32;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.amazonaws#aws-java-sdk;1.7.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.1 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.2 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.2 in central\n",
      "\tfound commons-codec#commons-codec;1.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.1.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.1.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.1.1 in central\n",
      "\tfound joda-time#joda-time;2.12.5 in central\n",
      "\t[2.12.5] joda-time#joda-time;[2.2,)\n",
      "\tfound org.apache.hadoop#hadoop-aws;2.7.3 in central\n",
      "\tfound org.apache.hadoop#hadoop-common;2.7.3 in central\n",
      "\tfound org.apache.hadoop#hadoop-annotations;2.7.3 in central\n",
      "\tfound com.google.guava#guava;11.0.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound commons-cli#commons-cli;1.2 in central\n",
      "\tfound org.apache.commons#commons-math3;3.1.1 in central\n",
      "\tfound xmlenc#xmlenc;0.52 in central\n",
      "\tfound commons-httpclient#commons-httpclient;3.1 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.4 in central\n",
      "\tfound commons-io#commons-io;2.4 in central\n",
      "\tfound commons-net#commons-net;3.1 in central\n",
      "\tfound commons-collections#commons-collections;3.2.2 in central\n",
      "\tfound javax.servlet#servlet-api;2.5 in central\n",
      "\tfound org.mortbay.jetty#jetty;6.1.26 in central\n",
      "\tfound org.mortbay.jetty#jetty-util;6.1.26 in central\n",
      "\tfound com.sun.jersey#jersey-core;1.9 in central\n",
      "\tfound com.sun.jersey#jersey-json;1.9 in central\n",
      "\tfound org.codehaus.jettison#jettison;1.1 in central\n",
      "\tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.2.2 in central\n",
      "\tfound javax.xml.stream#stax-api;1.0-2 in central\n",
      "\tfound javax.activation#activation;1.1 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-jaxrs;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-xc;1.9.13 in central\n",
      "\tfound com.sun.jersey#jersey-server;1.9 in central\n",
      "\tfound asm#asm;3.2 in central\n",
      "\tfound log4j#log4j;1.2.17 in central\n",
      "\tfound net.java.dev.jets3t#jets3t;0.9.0 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.2.5 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.2.5 in central\n",
      "\tfound com.jamesmurty.utils#java-xmlbuilder;0.4 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound commons-configuration#commons-configuration;1.6 in central\n",
      "\tfound commons-digester#commons-digester;1.8 in central\n",
      "\tfound commons-beanutils#commons-beanutils;1.7.0 in central\n",
      "\tfound commons-beanutils#commons-beanutils-core;1.8.0 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.10 in central\n",
      "\tfound org.apache.avro#avro;1.7.4 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.3 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.0.4.1 in central\n",
      "\tfound org.apache.commons#commons-compress;1.4.1 in central\n",
      "\tfound org.tukaani#xz;1.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound com.google.code.gson#gson;2.2.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-auth;2.7.3 in central\n",
      "\tfound org.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 in central\n",
      "\tfound org.apache.directory.server#apacheds-i18n;2.0.0-M15 in central\n",
      "\tfound org.apache.directory.api#api-asn1-api;1.0.0-M20 in central\n",
      "\tfound org.apache.directory.api#api-util;1.0.0-M20 in central\n",
      "\tfound org.apache.zookeeper#zookeeper;3.4.6 in central\n",
      "\tfound org.slf4j#slf4j-log4j12;1.7.10 in central\n",
      "\tfound io.netty#netty;3.6.2.Final in central\n",
      "\tfound org.apache.curator#curator-framework;2.7.1 in central\n",
      "\tfound org.apache.curator#curator-client;2.7.1 in central\n",
      "\tfound com.jcraft#jsch;0.1.42 in central\n",
      "\tfound org.apache.curator#curator-recipes;2.7.1 in central\n",
      "\tfound org.apache.htrace#htrace-core;3.1.0-incubating in central\n",
      "\tfound javax.servlet.jsp#jsp-api;2.1 in central\n",
      "\tfound jline#jline;0.9.94 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.2.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.2.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.2.3 in central\n",
      ":: resolution report :: resolve 3814ms :: artifacts dl 64ms\n",
      "\t:: modules in use:\n",
      "\tasm#asm;3.2 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk;1.7.4 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.2.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.2.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.2.3 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.2.4 from central in [default]\n",
      "\tcom.google.guava#guava;11.0.2 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcom.jamesmurty.utils#java-xmlbuilder;0.4 from central in [default]\n",
      "\tcom.jcraft#jsch;0.1.42 from central in [default]\n",
      "\tcom.sun.jersey#jersey-core;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-json;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-server;1.9 from central in [default]\n",
      "\tcom.sun.xml.bind#jaxb-impl;2.2.3-1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.3 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils;1.7.0 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils-core;1.8.0 from central in [default]\n",
      "\tcommons-cli#commons-cli;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.4 from central in [default]\n",
      "\tcommons-collections#commons-collections;3.2.2 from central in [default]\n",
      "\tcommons-configuration#commons-configuration;1.6 from central in [default]\n",
      "\tcommons-digester#commons-digester;1.8 from central in [default]\n",
      "\tcommons-httpclient#commons-httpclient;3.1 from central in [default]\n",
      "\tcommons-io#commons-io;2.4 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tcommons-net#commons-net;3.1 from central in [default]\n",
      "\tio.netty#netty;3.6.2.Final from central in [default]\n",
      "\tjavax.activation#activation;1.1 from central in [default]\n",
      "\tjavax.servlet#servlet-api;2.5 from central in [default]\n",
      "\tjavax.servlet.jsp#jsp-api;2.1 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.2.2 from central in [default]\n",
      "\tjavax.xml.stream#stax-api;1.0-2 from central in [default]\n",
      "\tjline#jline;0.9.94 from central in [default]\n",
      "\tjoda-time#joda-time;2.12.5 from central in [default]\n",
      "\tlog4j#log4j;1.2.17 from central in [default]\n",
      "\tnet.java.dev.jets3t#jets3t;0.9.0 from central in [default]\n",
      "\torg.apache.avro#avro;1.7.4 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.4.1 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.1.1 from central in [default]\n",
      "\torg.apache.curator#curator-client;2.7.1 from central in [default]\n",
      "\torg.apache.curator#curator-framework;2.7.1 from central in [default]\n",
      "\torg.apache.curator#curator-recipes;2.7.1 from central in [default]\n",
      "\torg.apache.directory.api#api-asn1-api;1.0.0-M20 from central in [default]\n",
      "\torg.apache.directory.api#api-util;1.0.0-M20 from central in [default]\n",
      "\torg.apache.directory.server#apacheds-i18n;2.0.0-M15 from central in [default]\n",
      "\torg.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-annotations;2.7.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-auth;2.7.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;2.7.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-common;2.7.3 from central in [default]\n",
      "\torg.apache.htrace#htrace-core;3.1.0-incubating from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.2.5 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.2.5 from central in [default]\n",
      "\torg.apache.zookeeper#zookeeper;3.4.6 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-jaxrs;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-xc;1.9.13 from central in [default]\n",
      "\torg.codehaus.jettison#jettison;1.1 from central in [default]\n",
      "\torg.mortbay.jetty#jetty;6.1.26 from central in [default]\n",
      "\torg.mortbay.jetty#jetty-util;6.1.26 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.10 from central in [default]\n",
      "\torg.slf4j#slf4j-log4j12;1.7.10 from central in [default]\n",
      "\torg.tukaani#xz;1.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.0.4.1 from central in [default]\n",
      "\txmlenc#xmlenc;0.52 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.1.1 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.2 by [org.apache.httpcomponents#httpclient;4.2.5] in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.2 by [org.apache.httpcomponents#httpcore;4.2.5] in [default]\n",
      "\tcommons-codec#commons-codec;1.6 by [commons-codec#commons-codec;1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.3 by [commons-codec#commons-codec;1.4] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.1.1 by [com.fasterxml.jackson.core#jackson-core;2.2.3] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.1.1 by [com.fasterxml.jackson.core#jackson-databind;2.2.3] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.1.1 by [com.fasterxml.jackson.core#jackson-annotations;2.2.3] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   76  |   1   |   0   |   8   ||   68  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f79a42e3-595b-4a4d-9069-c5348c381c32\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 68 already retrieved (0kB/31ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/10/12 15:54:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from financeComplaint.logger import logging\n",
    "from financeComplaint.exception import CustomException\n",
    "from financeComplaint.config.spark_manager import spark_session\n",
    "from pyspark.sql.functions import lit, col\n",
    "from financeComplaint.entity.schema import FinanceDataSchema\n",
    "from financeComplaint.entity.artifact_entity import DataValidationArtifact\n",
    "from pyspark.sql import DataFrame\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class MissingReport:\n",
    "    total_row: int\n",
    "    missing_row: list\n",
    "    missing_percentage: float\n",
    "\n",
    "COMPLAINT_TABLE = \"complaint\"\n",
    "ERROR_MESSAGE = \"error_msg\"\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self, config: DataValidationConfig, table_name: str = COMPLAINT_TABLE, schema=FinanceDataSchema()):\n",
    "        self.config = config\n",
    "        self.table_name = table_name\n",
    "        self.schema = schema\n",
    "\n",
    "    def read_data(self) -> DataFrame:\n",
    "        try:\n",
    "            dataframe: DataFrame = spark_session.read.parquet(self.config.feature_store_file_path)\n",
    "            logging.info(f\"Data frame is created using file: {self.config.feature_store_file_path}\")\n",
    "            logging.info(f\"Number of row: {dataframe.count()} and column: {len(dataframe.columns)}\")\n",
    "            # Why: only for cutting data size for testing\n",
    "            # Here, only 10 percent of data will be used\n",
    "            dataframe, _ = dataframe.randomSplit([0.1, 0.90])\n",
    "            return dataframe\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_missing_report(dataframe: DataFrame) -> Dict[str, MissingReport]:\n",
    "        try:\n",
    "            missing_report: Dict[str:MissingReport] = dict()\n",
    "            logging.info(f\"Preparing missing reports for each column\")\n",
    "            number_of_row = dataframe.count()\n",
    "            for column in dataframe.columns:\n",
    "                missing_row = dataframe.filter(f\"{column} is null\").count()\n",
    "                missing_percentage = (missing_row * 100) / number_of_row\n",
    "                missing_report[column] = MissingReport(total_row=number_of_row,\n",
    "                                                        missing_row=missing_row,\n",
    "                                                        missing_percentage=missing_percentage\n",
    "                                                        )\n",
    "            logging.info(f\"Missing report prepared: {missing_report}\")\n",
    "            return missing_report\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def get_unwanted_and_high_missing_value_columns(self, dataframe: DataFrame, threshold: float= 0.3) -> List[str]:\n",
    "        try:\n",
    "            missing_report: Dict[str, MissingReport] = self.get_missing_report(dataframe=dataframe)\n",
    "            unwanted_column: List[str] = self.schema.unwanted_columns\n",
    "            for column in missing_report:\n",
    "                if missing_report[column].missing_percentage > (threshold * 100):\n",
    "                    unwanted_column.append(column)\n",
    "                    logging.info(f\"Missing report {column}: [{missing_report[column]}]\")\n",
    "                unwanted_column = list(set(unwanted_column))\n",
    "            return unwanted_column\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    def drop_unwanted_columns(self, dataframe: DataFrame) -> DataFrame:\n",
    "        try:\n",
    "            unwanted_columns: List = self.get_unwanted_and_high_missing_value_columns(dataframe=dataframe, )\n",
    "            logging.info(f\"Dropping feature: {','.join(unwanted_columns)}\")\n",
    "            unwanted_dataframe: DataFrame = dataframe.select(unwanted_columns)\n",
    "\n",
    "            unwanted_dataframe = unwanted_dataframe.withColumn(ERROR_MESSAGE, lit(\"Contains many missing values\"))\n",
    "\n",
    "            rejected_dir = os.path.join(self.config.rejected_data_dir, \"missing_data\")\n",
    "            os.makedirs(rejected_dir, exist_ok=True)\n",
    "            file_path = os.path.join(rejected_dir, self.config.file_name)\n",
    "\n",
    "            logging.info(f\"Writing dropped column into file: [{file_path}]\")\n",
    "            unwanted_dataframe.write.mode(\"append\").parquet(file_path)\n",
    "            dataframe: DataFrame = dataframe.drop(*unwanted_columns)\n",
    "            logging.info(f\"Remaining number of columns: [{dataframe.columns}]\")\n",
    "            return dataframe\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_unique_values_of_each_column(dataframe: DataFrame) -> None:\n",
    "        try:\n",
    "            for column in dataframe.columns:\n",
    "                n_unique: int = dataframe.select(col(column)).distinct().count()\n",
    "                n_missing: int = dataframe.filter(col(column).isNull()).count()\n",
    "                missing_percentage: float = (n_missing * 100) / dataframe.count()\n",
    "                logging.info(f\"Column: {column} contains {n_unique} value and missing perc: {missing_percentage} %.\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "\n",
    "    def is_required_columns_exist(self, dataframe: DataFrame):\n",
    "        try:\n",
    "            columns = list(filter(lambda x: x in self.schema.required_columns,\n",
    "                                  dataframe.columns))\n",
    "\n",
    "            if len(columns) != len(self.schema.required_columns):\n",
    "                raise Exception(f\"Required column missing\\n\\\n",
    "                 Expected columns: {self.schema.required_columns}\\n\\\n",
    "                 Found columns: {columns}\\\n",
    "                 \")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    def initiate_data_validation(self) -> DataValidationArtifact:\n",
    "        try:\n",
    "            logging.info(f\"Initiating data preprocessing.\")\n",
    "            dataframe: DataFrame = self.read_data()            \n",
    "\n",
    "            logging.info(f\"Dropping unwanted columns\")\n",
    "            dataframe: DataFrame = self.drop_unwanted_columns(dataframe=dataframe)\n",
    "\n",
    "            # validation to ensure that all require column available\n",
    "            self.is_required_columns_exist(dataframe=dataframe)\n",
    "\n",
    "            logging.info(\"Saving preprocessed data.\")\n",
    "            print(f\"Row: [{dataframe.count()}] Column: [{len(dataframe.columns)}]\")\n",
    "            print(f\"Expected Column: {self.schema.required_columns}\\nPresent Columns: {dataframe.columns}\")\n",
    "\n",
    "            os.makedirs(self.config.accepted_data_dir, exist_ok=True)\n",
    "            accepted_file_path = os.path.join(self.config.accepted_data_dir,\n",
    "                                              self.config.file_name\n",
    "                                              )\n",
    "            dataframe.write.parquet(accepted_file_path)\n",
    "\n",
    "            artifact = DataValidationArtifact(accepted_data_file_path= accepted_file_path,\n",
    "                                              rejected_data_dir= self.config.rejected_data_dir\n",
    "                                              )\n",
    "            logging.info(f\"Data validation artifact: [{artifact}]\")\n",
    "            return artifact\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from financeComplaint.exception import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: [87675] Column: [13]\n",
      "Expected Column: ['consumer_disputed', 'company_response', 'consumer_consent_provided', 'submitted_via', 'issue', 'date_sent_to_company', 'date_received']\n",
      "Present Columns: ['company', 'company_response', 'consumer_consent_provided', 'consumer_disputed', 'date_received', 'date_sent_to_company', 'issue', 'product', 'state', 'sub_issue', 'submitted_via', 'timely', 'zip_code']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    data_validation = DataValidation(config=data_validation_config)\n",
    "    data_validation.initiate_data_validation()\n",
    "except Exception as e:\n",
    "    raise CustomException(e, sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
